import numpy as np
import matplotlib.pyplot as plt

def dp_regression(data, b, eps):
    """
    Compute a differentially private regression estimate for beta = S_xy / S_xx.
    
    Parameters:
        data: numpy array of shape (n,2), each row is (x_i, y_i)
        b: clipping bound; each x_i and y_i are clipped to lie in [-b, b]
        eps: overall privacy parameter
        
    Returns:
        dp_beta: differentially private estimate of beta.
    """
    # Clip the data to the interval [-b, b]
    clipped_data = np.clip(data, -b, b)
    x = clipped_data[:, 0]
    y = clipped_data[:, 1]
    
    # Compute the sufficient statistics
    S_xy = np.sum(x * y)
    S_xx = np.sum(x * x)
    
    # Sensitivities (with one row change):
    # Sensitivity for S_xy is 2*b^2, for S_xx is b^2.
    # Split the privacy budget equally: eps1 = eps/2, eps2 = eps/2.
    # Hence, noise scale for S_xy: 2*b^2 / (eps/2) = 4*b^2/eps,
    # and for S_xx: b^2 / (eps/2) = 2*b^2/eps.
    scale_xy = 4 * b**2 / eps
    scale_xx = 2 * b**2 / eps
    
    noisy_S_xy = S_xy + np.random.laplace(loc=0, scale=scale_xy)
    noisy_S_xx = S_xx + np.random.laplace(loc=0, scale=scale_xx)
    
    # Avoid division by zero (or very small denominator)
    if np.abs(noisy_S_xx) < 1e-6:
        return 0
    dp_beta = noisy_S_xy / noisy_S_xx
    return dp_beta

def ols_regression(data):
    """
    Compute the ordinary least squares (OLS) regression estimate beta = S_xy / S_xx.
    
    Parameters:
        data: numpy array of shape (n,2), each row is (x_i, y_i)
        
    Returns:
        beta: OLS estimate of beta.
    """
    x = data[:, 0]
    y = data[:, 1]
    S_xy = np.sum(x * y)
    S_xx = np.sum(x * x)
    if S_xx == 0:
        return 0
    return S_xy / S_xx

# Monte Carlo simulation parameters
eps = 0.1    # privacy parameter
b = 1        # clipping bound
num_trials = 1000  # number of Monte Carlo trials for each sample size
n_values = np.arange(100, 5001, 100)  # sample sizes from 100 to 5000

# Lists to store bias and standard deviation for OLS and DP estimates
ols_bias = []
ols_std = []
dp_bias = []
dp_std = []

# True regression slope is 1
true_beta = 1

for n in n_values:
    ols_estimates = []
    dp_estimates = []
    for _ in range(num_trials):
        # Generate synthetic data:
        # x_i ~ Uniform(-0.5, 0.5)
        x = np.random.uniform(-0.5, 0.5, size=n)
        # y_i = x_i + Gaussian noise, where noise ~ N(0, 0.02)
        # Here, standard deviation = sqrt(0.02)
        noise = np.random.normal(0, np.sqrt(0.02), size=n)
        y = x + noise
        
        # Combine into an (n x 2) data array
        data = np.column_stack((x, y))
        
        # Compute the non-private OLS estimate and the DP estimate
        beta_hat = ols_regression(data)
        beta_dp = dp_regression(data, b, eps)
        
        ols_estimates.append(beta_hat)
        dp_estimates.append(beta_dp)
    
    # Convert lists to numpy arrays for computation
    ols_estimates = np.array(ols_estimates)
    dp_estimates = np.array(dp_estimates)
    
    # Compute bias (mean error relative to true_beta) and standard deviation
    ols_bias.append(np.mean(ols_estimates - true_beta))
    dp_bias.append(np.mean(dp_estimates - true_beta))
    ols_std.append(np.std(ols_estimates))
    dp_std.append(np.std(dp_estimates))

# Convert the collected results to numpy arrays
ols_bias = np.array(ols_bias)
dp_bias = np.array(dp_bias)
ols_std = np.array(ols_std)
dp_std = np.array(dp_std)

# Plotting the results
plt.figure(figsize=(12, 6))

# Plot bias as a function of sample size
plt.subplot(1, 2, 1)
plt.plot(n_values, ols_bias, label='OLS Bias', marker='o')
plt.plot(n_values, dp_bias, label='DP Bias', marker='o')
plt.axhline(0, color='black', linestyle='--')
plt.ylim(-1.0, 1.0)
plt.xlabel('Sample Size (n)')
plt.ylabel('Bias (Mean Error)')
plt.title('Bias vs Sample Size')
plt.legend()

# Plot standard deviation as a function of sample size
plt.subplot(1, 2, 2)
plt.plot(n_values, ols_std, label='OLS Std', marker='o')
plt.plot(n_values, dp_std, label='DP Std', marker='o')
plt.ylim(0, 1.0)  # standard deviation is always non-negative
plt.xlabel('Sample Size (n)')
plt.ylabel('Standard Deviation')
plt.title('Standard Deviation vs Sample Size')
plt.legend()

plt.tight_layout()
plt.show()